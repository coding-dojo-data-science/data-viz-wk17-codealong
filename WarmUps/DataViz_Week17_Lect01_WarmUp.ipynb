{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP60vOxm6Ct8oSRwcvyNC8B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coding-dojo-data-science/data-viz-wk17-codealong/blob/main/WarmUps/DataViz_Week17_Lect01_WarmUp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔥 DataViz: Week 17, Lecture 01 - Warm Up"
      ],
      "metadata": {
        "id": "rjoRPHPZcoLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 01/24/22\n"
      ],
      "metadata": {
        "id": "q4jXZ-KUp5F1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🗺️ INSTRUCTIONS"
      ],
      "metadata": {
        "id": "Y4vdcZolpgmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">- Run the code in this notebook to create and evaluate the Linear Regression model at the bottom. \n",
        "  - `Runtime` menu > `Run All`\n",
        "- Scroll down to the regression model results and\n",
        "- Answer the questions below the model and be prepared to discuss with the class.\n",
        "\n",
        "[Click here](#warmup)"
      ],
      "metadata": {
        "id": "UySOK6JhplE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: this notebook **does NOT follow best practices** (minimal EDA, removing outliers before train/test split, etc.). It is meant for discussion purposes.\n"
      ],
      "metadata": {
        "id": "-Ggi_OumkZts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CODE \n"
      ],
      "metadata": {
        "id": "90-G6IQGkkJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Updating Scikit-Learn to V 1.1.3"
      ],
      "metadata": {
        "id": "LHJaDGEXkeAr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdoqpu5pckGa"
      },
      "outputs": [],
      "source": [
        "## UPDATING SKLEARN ON COLAB\n",
        "!pip install scikit-learn==1.1.3\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "import sklearn as sk\n",
        "vers = !python --version\n",
        "print(f\"Python Vers: {vers[0]}\")\n",
        "print(f\"Scikit-learn Vers: {sk.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Import Standard Packages\n",
        "import os, sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "fav_style = ('ggplot','tableau-colorblind10')\n",
        "fav_context  ={'context':'notebook', 'font_scale':1.1}\n",
        "plt.style.use(fav_style)\n",
        "sns.set_context(**fav_context)\n",
        "plt.rcParams['savefig.transparent'] = False\n",
        "plt.rcParams['savefig.bbox'] = 'tight'"
      ],
      "metadata": {
        "id": "d159X9NKcsiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocessing Imports ([ ] TO DO: Consider making preprocess_imports module)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import (make_column_transformer, make_column_selector, \n",
        "                             ColumnTransformer)\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "##import statsmodels correctly\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "\n",
        "## fixing random for lesson generation\n",
        "SEED = 321\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "H5Ha7oLBpIiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_regression(model, X_train,y_train, X_test, y_test,as_frame=True): \n",
        "  \"\"\"Evaluates a scikit learn regression model using r-squared and RMSE. \n",
        "  Returns the results a DataFrame if as_frame is True (Default).\n",
        "  \"\"\"\n",
        "  ## Training Data\n",
        "  y_pred_train = model.predict(X_train)\n",
        "  r2_train = metrics.r2_score(y_train, y_pred_train)\n",
        "  rmse_train = metrics.mean_squared_error(y_train, y_pred_train, \n",
        "                                          squared=False)\n",
        "  mae_train = metrics.mean_absolute_error(y_train, y_pred_train)\n",
        "\n",
        "\n",
        "  ## Test Data\n",
        "  y_pred_test = model.predict(X_test)\n",
        "  r2_test = metrics.r2_score(y_test, y_pred_test)\n",
        "  rmse_test = metrics.mean_squared_error(y_test, y_pred_test, \n",
        "                                          squared=False)\n",
        "  mae_test = metrics.mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "  ## if returning a dataframe:\n",
        "  if as_frame:\n",
        "      df_version =[['Split','R^2','MAE','RMSE']]\n",
        "      df_version.append(['Train',r2_train, mae_train, rmse_train])\n",
        "      df_version.append(['Test',r2_test, mae_test, rmse_test])\n",
        "      df_results = pd.DataFrame(df_version[1:], columns=df_version[0])\n",
        "      df_results = df_results.round(2)\n",
        "\n",
        "\n",
        "      # adapting hide_index for pd version\n",
        "      if pd.__version__ < \"1.4.0\":\n",
        "        display(df_results.style.hide_index().format(precision=2, thousands=','))\n",
        "      else:\n",
        "        display(df_results.style.hide(axis='index').format(precision=2, thousands=','))\n",
        "\n",
        "  ## If not dataframe, just print results.    \n",
        "  else: \n",
        "      print(f\"Training Data:\\tR^2 = {r2_train:,.2f}\\tRMSE = {rmse_train:,.2f}\\tMAE = {mae_train:,.2f}\")\n",
        "      print(f\"Test Data:\\tR^2 = {r2_test:,.2f}\\tRMSE = {rmse_test:,.2f}\\tMAE = {mae_test:,.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "def plot_residuals(model,X_test_df, y_test,figsize=(12,5)):\n",
        "  \"\"\"Plots a Q-Q Plot and residual plot for a regression model.\n",
        "  \"\"\"\n",
        "  ## Make predictions and calculate residuals\n",
        "  y_pred = model.predict(X_test_df)\n",
        "  resid = y_test - y_pred\n",
        "\n",
        "  fig, axes = plt.subplots(ncols=2,figsize=figsize)\n",
        "\n",
        "  ## Normality \n",
        "  sm.graphics.qqplot(resid, line='45',fit=True,ax=axes[0]);\n",
        "\n",
        "  ## Homoscedascity\n",
        "  ax = axes[1]\n",
        "  ax.scatter(y_pred, resid, edgecolor='white',lw=0.5)\n",
        "  ax.axhline(0,zorder=0)\n",
        "  ax.set(ylabel='Residuals',xlabel='Predicted Value');\n",
        "  fig.suptitle(\"Residual Plots\", y=1.01)\n",
        "  plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "rII7ZrkRg8LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "L-yOxZmFczMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load in data\n",
        "FILE = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSEZQEzxja7Hmj5tr5nc52QqBvFQdCAGb52e1FRK1PDT2_TQrS6rY_TR9tjZjKaMbCy1m5217sVmI5q/pub?output=csv\"\n",
        "df = pd.read_csv(FILE)\n",
        "\n",
        "# setting index & dropping \n",
        "# df = df.set_index('id')\n",
        "use_cols = ['bedrooms','bathrooms','sqft_living','yr_built','waterfront',\n",
        "            'floors','price']\n",
        "df = df[use_cols].copy()\n",
        "df.info()\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "MFaaCxHCc3JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "5SAu5M6gktT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> This notebook does NOT follow best practices (minimal EDA, removing outliers before train/test split, etc.)"
      ],
      "metadata": {
        "id": "7LehGyEalsE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "Sq2eF_BMjxFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "1uRhp5WapWpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the Target"
      ],
      "metadata": {
        "id": "n-qmAeDAk8KC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting histogram and boxplot together\n",
        "target = 'price'\n",
        "grid_spec = {'height_ratios':[0.7,0.3]}\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, figsize=(10,6), \n",
        "                         gridspec_kw=grid_spec)\n",
        "axes[0].set_title(f\"Distribution of {target}\")\n",
        "\n",
        "sns.histplot(data=df, x=target, ax=axes[0])\n",
        "sns.boxplot(data=df, x=target, ax=axes[1])"
      ],
      "metadata": {
        "id": "a4ahq08-lTTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ef87ce6"
      },
      "source": [
        "- This dataset is known to be a tricky regression without addressing assumptions of linear regression.\n",
        "- Doing a M.V.P. removal of outliers, just from target."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Removing Outliers from Target"
      ],
      "metadata": {
        "id": "uvnqCb22lnRp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a71e1854"
      },
      "outputs": [],
      "source": [
        "## find outliers \n",
        "idx_outliers = np.abs(stats.zscore(df[target]) )>3\n",
        "idx_outliers.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "cf023e59"
      },
      "outputs": [],
      "source": [
        "# saving non-outliers\n",
        "df = df[~idx_outliers].copy()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93040776"
      },
      "outputs": [],
      "source": [
        "# visualizing final target\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, figsize=(10,6), \n",
        "                         gridspec_kw=grid_spec)\n",
        "axes[0].set_title(f\"Distribution of {target} (Outliers Removed\")\n",
        "\n",
        "sns.histplot(data=df, x=target, ax=axes[0])\n",
        "sns.boxplot(data=df, x=target, ax=axes[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA: Features vs Target"
      ],
      "metadata": {
        "id": "uO_F6hXjl9d1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig_pairplot = sns.pairplot(df,y_vars='price');\n",
        "fig_pairplot"
      ],
      "metadata": {
        "id": "9G6X2_NgktKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_corr,ax = plt.subplots(figsize=(8,7))\n",
        "sns.heatmap(df.corr(), annot=True, fmt= \".2g\",cmap='coolwarm', ax=ax);\n",
        "ax.set_title(\"Correlation Heatmap\");"
      ],
      "metadata": {
        "id": "akrcA5UtlJLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "LFbGE_8qgwjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## define X/y and train-test-split\n",
        "target='price'\n",
        "y = df[target].copy()\n",
        "X = df.drop(columns=target).copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=SEED)\n",
        "\n",
        "\n",
        "## make categorical preprocessing pipeline\n",
        "cat_sel = make_column_selector(dtype_include='object')\n",
        "\n",
        "cat_pipe = make_pipeline( SimpleImputer(strategy='constant', \n",
        "                                        fill_value='MISSING'),\n",
        "                         OneHotEncoder(drop='first',\n",
        "                                       sparse=False)\n",
        "                        )\n",
        "\n",
        "\n",
        "## make numeric preprocessing pipeline\n",
        "num_sel = make_column_selector(dtype_include='number')\n",
        "\n",
        "num_pipe = make_pipeline( SimpleImputer(strategy='mean'))"
      ],
      "metadata": {
        "id": "4fy37zD_g3-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "962fba2b"
      },
      "source": [
        ">- Note: So far, all of the code should be familiar to you. \n",
        "    -  With sklearn v1.1+, you should always add `verbose_feature_names_out=False` to column transformers *`ColumnTransformer`/ `make_column_transformer`)\n",
        "        - (If you want to see what the verbose version looks like feel free to give it a try!)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## make the preprocessing column transformer\n",
        "preprocessor = make_column_transformer( (num_pipe, num_sel),\n",
        "                                        (cat_pipe,cat_sel),                                      \n",
        "                                       verbose_feature_names_out=False)\n",
        "preprocessor"
      ],
      "metadata": {
        "id": "t2liZV_zg6cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Fit preprocessor and get feature names\n",
        "preprocessor.fit(X_train)\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "feature_names"
      ],
      "metadata": {
        "id": "nALFDP-WPiGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### PREP ALL X VARS AS DATAFRAMES\n",
        "## Prepare X_train_df\n",
        "X_train_df = pd.DataFrame( preprocessor.fit_transform(X_train), \n",
        "                          columns = feature_names,\n",
        "                         index = X_train.index)\n",
        "\n",
        "## Prepare X_test_df\n",
        "X_test_df = pd.DataFrame( preprocessor.transform(X_test),\n",
        "                          columns = feature_names,\n",
        "                         index=X_test.index)\n",
        "X_train_df"
      ],
      "metadata": {
        "id": "h93LpCcJol09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"warmup\"></a>"
      ],
      "metadata": {
        "id": "4kgaa91ByUs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"warmup\"></a>\n",
        "# 🔥 **Warm-Up Questions** \n"
      ],
      "metadata": {
        "id": "rSYju9p1qiEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression"
      ],
      "metadata": {
        "id": "lzpemNtSick_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Features Used\n",
        "X_train_df.head(3)"
      ],
      "metadata": {
        "id": "cQLW_HegirfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_df,y_train)"
      ],
      "metadata": {
        "id": "ekmEBCP7iCPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions to Answer - Part 1: Model Metrics"
      ],
      "metadata": {
        "id": "S8eVHMLysISC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## evaluate model\n",
        "evaluate_regression(lin_reg, X_train_df, y_train, \n",
        "                    X_test_df, y_test)\n"
      ],
      "metadata": {
        "id": "LRN8Eyorouha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> Use the cells below to answer the following questions:\n",
        "\n",
        "- **Q1: Does this model have a good MAE?**\n",
        "  - ...\n",
        "- **Q2: Does this model have a good R-squared?**\n",
        "  - ...\n",
        "\n",
        "- **Q3: Is this model overfit, under fit, or neither?**\n",
        "  - ..."
      ],
      "metadata": {
        "id": "ysOFAnaCqvBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions to Answer - Part 2: Assumptions of Linear Regression"
      ],
      "metadata": {
        "id": "avXLvNLMux8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Use the visualizations below to answer the following questions:\n",
        "\n",
        "- **Q4: Does this regression meet the assumptions of Linear Regression:**\n",
        "  - 1) Little to no multicollinearity:\n",
        "    - ...\n",
        "  - 2) Features have a linear relation with the target.\n",
        "    - ...\n",
        "  - 3) Homoscedasticity\n",
        "    - ...\n",
        "  - 4) Normally Distributed Residuals\n",
        "    - ...\n",
        "\n"
      ],
      "metadata": {
        "id": "EcFXyVD7ryU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig_corr"
      ],
      "metadata": {
        "id": "9Lqp8M1jvMtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Using a pairgrid \n",
        "# https://seaborn.pydata.org/tutorial/axis_grids.html#plotting-pairwise-data-relationships\n",
        "features= df.drop(columns=target).columns\n",
        "pair_g = sns.PairGrid(df, y_vars=[\"price\"], x_vars=features)\n",
        "pair_g.map(sns.regplot,\n",
        "      scatter_kws={'ec':'white','lw':0.5},\n",
        "      line_kws={'color':'red','ls':':','lw':2});"
      ],
      "metadata": {
        "id": "SJ4H92nOsWVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_residuals(lin_reg, X_test_df,y_test)"
      ],
      "metadata": {
        "id": "mUZNRu6orzm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Questions to Answer (if you can)"
      ],
      "metadata": {
        "id": "i5tk1jV4v0j6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Q5: What features made the model predict a higher price?\n",
        "  - ...\n",
        "\n",
        "- Q6: Which feature made the model predict a lower price?\n",
        "  - ...\n",
        "- Q7:  What effect does having more bathrooms have on predicted price?\n",
        "  - ...\n"
      ],
      "metadata": {
        "id": "wirlEX0qqxos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Return to the main zoom room once you've answered the questions."
      ],
      "metadata": {
        "id": "rKqnROoC_gDU"
      }
    }
  ]
}